generation:
  num_subsamples: 5
  num_demos: 5
  num_prompts_per_subsample: 50
  model:
    name: LLAMA_forward
    batch_size: 500
    gpt_config:
      model: C:\Users\LSH\Desktop\Meta-Llama-3-8B-Instruct.Q4_K_M.gguf
      temperature: 0.7
      max_tokens: 50
      top_p: 1.0
      frequency_penalty: 0.0
      presence_penalty: 0.0

evaluation:
  method: likelihood
  num_samples: 50
  num_few_shot: 5
  model:
    name: LLAMA_forward
    batch_size: 500
    gpt_config:
      model: C:\Users\LSH\Desktop\Meta-Llama-3-8B-Instruct.Q4_K_M.gguf
      temperature: 0.7
      max_tokens: 300
      top_p: 1.0
      frequency_penalty: 0.0
      presence_penalty: 0.0

demo:
  model:
    name: LLAMA_forward
    batch_size: 500
    gpt_config:
      model: C:\Users\LSH\Desktop\Meta-Llama-3-8B-Instruct.Q4_K_M.gguf
      temperature: 0.7
      max_tokens: 300
      top_p: 1.0
      frequency_penalty: 0.0
      presence_penalty: 0.0

